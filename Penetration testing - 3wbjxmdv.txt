import sys
import os
import requests
import random
import time
import logging
from multiprocessing import cpu_count
from multiprocessing.dummy import Pool

# Logging setup
logging.basicConfig(filename='scanner.log', level=logging.INFO, format='%(asctime)s - %(message)s')

# Safety: Define the authorized list of sites
authorized_sites = ['example.com', 'testsite.com']  # Replace with real authorized sites

# Validate if a site is authorized
def is_authorized_site(site, authorized_sites):
    return site in authorized_sites

# Safe request handling with retry on failure
def safe_request(url, headers, timeout=10):
    try:
        response = requests.get(url, headers=headers, verify=False, timeout=timeout)
        return response
    except requests.exceptions.RequestException as e:
        logging.error(f"Error with request {url}: {e}")
        return None

# Scan logic
def scan_site(site, headers):
    domain = site.split('/')[0]  # Extract domain
    paths = ['path1', 'path2']  # List of paths to scan (e.g., common attack paths)
    shell_signatures = ['shell_signature1', 'shell_signature2']  # List of known shell signatures

    for path in paths:
        url = f"http://{domain}/{path}"
        response = safe_request(url, headers)
        if response and any(sig in response.text for sig in shell_signatures):
            logging.info(f"Shell found at {url}")
            print(f"[+] Found shell at {url}")
            return True  # Exit on first match
        time.sleep(random.uniform(1, 3))  # Throttling to prevent DoS
    return False

# Main scanning function
def run_scanner(site):
    if is_authorized_site(site, authorized_sites):
        logging.info(f"Scanning {site}...")
        headers = {'User-Agent': 'Mozilla/5.0'}
        if not scan_site(site, headers):
            logging.info(f"Failed to find shell at {site}")
            print(f"[!] Failed to find shell at {site}")
    else:
        print(f"[!] Unauthorized site: {site}")

# Main script entry point
if __name__ == "__main__":
    target_sites = ['example.com', 'testsite.com']  # Replace with actual target list
    thread_count = cpu_count() * 2  # Number of threads to use
    print(f"Using {thread_count} threads for scanning.")
    
    pool = Pool(thread_count)
    pool.map(run_scanner, target_sites)
    pool.close()
    pool.join()
    
    print("[+] Scanning complete.")